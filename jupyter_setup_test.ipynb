{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for required python libraries...\n",
      "findspark already installed and successfully imported\n",
      "pyspark already installed and successfully imported\n",
      "random already installed and successfully imported\n",
      "pandas already installed and successfully imported\n",
      "numpy already installed and successfully imported\n",
      "sparknlp already installed and successfully imported\n",
      "webbrowser already installed and successfully imported\n"
     ]
    }
   ],
   "source": [
    "import pip\n",
    "import sys\n",
    "\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(package + \" already installed and successfully imported\")\n",
    "    except ImportError:\n",
    "        print(package + \" not found. Installing...\")\n",
    "        pip.main(['install', package])\n",
    "        try:\n",
    "            print(\"importing \"+package)\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            print(\"ERROR: unable to automatically install package: \" + package)\n",
    "            print(\"Please install manually and run this script again\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "\n",
    "print(\"checking for required python libraries...\")\n",
    "import_or_install('findspark')\n",
    "import_or_install('pyspark')\n",
    "import_or_install('random')\n",
    "import_or_install('pandas')\n",
    "import_or_install('numpy')\n",
    "import_or_install('sparknlp')\n",
    "import_or_install('webbrowser')\n",
    "import_or_install('os')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "n_CPUs = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------+\n",
      "|_1                       |_2                  |\n",
      "+-------------------------+--------------------+\n",
      "|Spark_Properly_Configured|You are ready to go!|\n",
      "+-------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession         \n",
    "         .builder.master(\"local[\"+str(n_CPUs)+\"]\")\n",
    "         .config(\"spark.driver.cores\", str(n_CPUs))\n",
    "         .config(\"spark.driver.memory\", \"58g\")\n",
    "         .config(\"spark.executor.memory\",\"6g\")\n",
    "         .config(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "         .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.1.0\")\n",
    "         .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.1.0,com.johnsnowlabs.nlp:spark-nlp-ocr_2.11:2.1.0\")\n",
    "         .config(\"spark.jars.repositories\",\"http://repo.spring.io/plugins-release/\")\n",
    "         .getOrCreate())\n",
    "\n",
    "\n",
    "output = [(' Spark Properly Configured for Jupyter Notebooks ', ' You are ready to go! ')]\n",
    "\n",
    "spark.createDataFrame(output).show(truncate = False)\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
